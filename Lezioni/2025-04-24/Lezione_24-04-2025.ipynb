{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534256dd",
   "metadata": {},
   "source": [
    "# 1. Classificazione SoftMax\n",
    "\n",
    "Abbiamo visto come sia possibile \"trasformare\" un regressore lineare in un classificatore binario utilizzando la funzione logistica. Abbiamo anche visto che è possibile implementare un classificatore multiclasse mediante il principio \"one-vs-all\". Tuttavia, il principio one-vs-all è poco naturale per risolvere problemi di classificazione multiclasse. Un regressore logistico ci permette di stimare la probabilità:\n",
    "\n",
    "$$\n",
    "p(c \\mid x) \\tag{1}\n",
    "$$\n",
    "\n",
    "dove $c$ è la classe ($c = 0$ nel caso della classe negativa e $c = 1$ nel caso della classe positiva) e $x$ è il campione in ingresso. Sappiamo inoltre che\n",
    "\n",
    "$$\n",
    "p(c = 0 \\mid x) + p(c = 1 \\mid x) = 1 \\tag{2}\n",
    "$$\n",
    "\n",
    "per cui il un regressore logistico ci permette di stimare la distribuzione di probabilità condizionale sulle classi possibili (solo due in questo caso), dato il campione in ingresso $x$.\n",
    "\n",
    "Supponiamo adesso di avere un problema di classificazione su $K$ classi $c = 0, c = 1, \\ldots, c = K - 1$. Il principio \"one-vs-all\" ci permette di classificare gli elementi $x$, ma non di stimare direttamente una distribuzione di probabilità condizionale sulle classi dato il campione in ingresso mostrato di seguito:\n",
    "\n",
    "$$\n",
    "p(c \\mid x) : p(c = 0 \\mid x) + p(c = 1 \\mid x) + \\ldots + p(c = K \\mid x) = 1 \\tag{3}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Domanda 1\n",
    "\n",
    "> A cosa può servire stimare le probabilità a posteriori $p(c \\mid x)$ oltre a inferire la classe più probabile per il campione $x$ ?\n",
    "\n",
    "Stimare le probabilità a posteriori $p(c \\mid x)$ serve non solo a determinare la classe più probabile, ma offre diversi vantaggi pratici e teorici:\n",
    "\n",
    "1. Decisioni più informate: conoscere la probabilità associata a ciascuna classe permette di valutare la confidenza del modello nella sua previsione. Ad esempio, una predizione con $p = 0.99$ è molto più affidabile di una con $p = 0.51$, anche se entrambe indicano la stessa classe più probabile.\n",
    "\n",
    "2. Classificazione con soglie personalizzate: in problemi dove gli errori hanno costi diversi (es. medicina, finanza), le probabilità permettono di definire soglie di decisione più adatte al contesto, anziché classificare sempre in base alla massima probabilità.\n",
    "\n",
    "3. Integrazione in sistemi complessi: le probabilità a posteriori possono essere usate in modelli probabilistici più grandi (es. reti bayesiane, modelli sequenziali) o come input in sistemi decisionali, dove è utile avere una stima di incertezza.\n",
    "\n",
    "4. Valutazione più dettagliata dei modelli: l’uso di probabilità consente metriche più raffinate come log-loss, cross-entropy, curva ROC e AUC, e permette di verificare se il modello è ben calibrato (cioè se le probabilità stimate corrispondono a frequenze reali).\n",
    "\n",
    "5. Combinazione di modelli: in metodi di ensemble learning o model averaging, è utile combinare probabilità (soft voting) piuttosto che semplici decisioni secche (hard voting), ottenendo spesso migliori performance.\n",
    "\n",
    "In sintesi, stimare $p(c \\mid x)$ consente un uso più flessibile, robusto e informato dei modelli di classificazione, andando ben oltre la sola scelta della classe più probabile.\n",
    "\n",
    "---\n",
    "\n",
    "Se volessimo ottenere una distribuzione di probabilità sulle $K$ classi, potremmo pensare di costruire un regressore lineare che, preso in input un dato, restituisce un vettore di $K$ elementi. Ciò può essere ottenuto semplicemente con una trasformazione lineare del tipo $z = Ax + b$, dove $A$ è una matrice $n \\times K$, con $n$ numero di feature in ingresso. Analogamente a quanto visto nel caso del regressore logistico, tuttavia, non vi è alcuna garanzia che il vettore $z$ rappresenti una valida distribuzione di probabilità. Ricordiamo che affinché ciò accada ci serve che:\n",
    "\n",
    "* $z_i \\ge 0, \\ \\forall i \\in \\{1, \\ldots, K\\}$\n",
    "* $\\sum_{i=1}^K z_i = 1$\n",
    "\n",
    "La funzione SoftMax è una generalizzazione della funzione logistica che ci permette di normalizzare un vettore arbitrario di numeri in modo che rispetti le due proprietà appena viste:\n",
    "\n",
    "$$\n",
    "\\sigma(x_j) = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}} \\tag{4}\n",
    "$$\n",
    "\n",
    "dove $z_j$ rappresenta la $j$-esima componente del vettore $z$ (e dunque $\\sigma(x_j)$ rappresenta la $j$-esima componente del vettore normalizzato mediante SoftMax $\\sigma(x)$).\n",
    "\n",
    "In pratica, la funzione SoftMax esegue due operazioni:\n",
    "\n",
    "* Applica la funzione esponenziale a tutte le componenti del vettore non normalizzato $z$. Questa operazione permette di soddisfare la prima proprietà mappando numeri $x \\in [-\\infty, +\\infty]$ su numeri del range $[0, +\\infty]$. Si noti che la funzione esponenziale è monotona crescente, per cui se $z_i \\le z_j$, allora $e^{z_i} \\le e^{z_j}$.\n",
    "* Normalizza gli elementi del vettore in uscita dividendoli per la somma dei valori positivi $e^{z_i} \\left( \\frac{e^zi}{\\sum{z_k}} \\right)$. Questa normalizzazione ci assicura che la seconda proprietà sia rispettata: $\\sum_{i=1}^K \\sigma(z_i) = 1$.\n",
    "\n",
    "### Domanda 2\n",
    "\n",
    "> Cosa garantisce che i valori restituiti dalla funzione SoftMax siano non negativi? Disegnare la funzione esponenziale per rispondere alla domanda.\n",
    "\n",
    "I valori restituiti dalla funzione SoftMax sono sempre non negativi perché la funzione applica, come primo passo, l’esponenziale a ciascun elemento del vettore $z$. La funzione esponenziale $f(z) = e^z$ ha la proprietà fondamentale di essere sempre positiva per ogni valore reale di $z$, cioè:\n",
    "\n",
    "$$\n",
    "e^z > 0 \\quad \\text{per ogni } z \\in \\mathbb{R}\n",
    "$$\n",
    "\n",
    "Questo significa che, anche se un componente $z_j$ è negativo, $e^{z_j}$ sarà comunque positivo (sebbene molto vicino a zero per valori molto negativi). La SoftMax calcola poi:\n",
    "\n",
    "$$\n",
    "\\sigma(z_j) = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}\n",
    "$$\n",
    "\n",
    "dove:\n",
    "\n",
    "* Il numeratore $e^{z_j}$ è positivo;\n",
    "* Il denominatore è una somma di termini $e^{z_k}$, tutti positivi, quindi positivo anch’esso.\n",
    "\n",
    "Essendo quindi il rapporto tra due numeri positivi, ogni componente della SoftMax è strettamente positiva (cioè maggiore di zero), e dunque non negativa. Inoltre, la normalizzazione garantisce che la somma dei valori sia uguale a 1, rendendo il vettore un’autentica distribuzione di probabilità.\n",
    "\n",
    "La forma della funzione esponenziale giustifica questo comportamento:\n",
    "![grafico](/Users/vincenzovillanova/Desktop/ML/grafico.jpg)\n",
    "\n",
    "Come mostra il grafico, la funzione $e^z$ è sempre positiva e monotona crescente, motivo per cui la SoftMax può garantire che tutti i valori siano non negativi e sommati diano 1.\n",
    "\n",
    "---\n",
    "\n",
    "La formulazione del regressore SoftMax è dunque la seguente:\n",
    "\n",
    "$$\n",
    "f(x) = \\sigma(Ax + b) = \\sigma(z) = \\frac{e^{z_j}}{\\sum_{k=1}^{K} e^{z_k}} \\tag{5}\n",
    "$$\n",
    "\n",
    "dove $z = Ax + b$, la funzione $f$ stima la probabilità a posteriori che $x$ appartenga ad una data classe:\n",
    "\n",
    "$$\n",
    "p(c = i \\mid x) = f(x)_i \\tag{6}\n",
    "$$\n",
    "\n",
    "e $f(x)_i$ indica la i-esima componente del vettore di probabilità ottenuto mediante il regressore softmax $f$.\n",
    "\n",
    "Per allenare il regressore softmax, utilizziamo una generalizzazione della loss vista nel caso del regressore logistico: la cross entropy loss.\n",
    "In teoria dell’informazione, la cross entropy tra due distribuzioni di probabilità $p$ e $q$ è definita come:\n",
    "\n",
    "$$\n",
    "H(p, q) = -\\sum_x p(x) \\log q(x) \\tag{7}\n",
    "$$\n",
    "\n",
    "La cross entropy $H(p, q)$ indica il numero medio di bit necessario per identificare eventi $x$ che seguono la probabilità $p$ se li descriviamo con la probabilità stimata $q$.\n",
    "La cross entropy raggiunge il suo minimo quando $p$ e $q$ sono uguali. In tal caso la cross entropy corrisponde all’entropia di $p$:\n",
    "\n",
    "$$\n",
    "H(p) = -\\sum_x p(x) \\log p(x) \\tag{8}\n",
    "$$\n",
    "\n",
    "Nel nostro caso, la probabilità $q$ è data dal regressore softmax, mentre $p$ rappresenta la probabilità “ideale” che il campione $x$ appartenga a una data classe.\n",
    "Dato che conosciamo le classi di appartenenza di ogni campione, la probabilità ideale è data da una rappresentazione di tipo \"one-hot-vector\", in cui $p(x) = \\mathbf{y}$ e y ha una unica componente $y_j = 1$, mentre tutte le altre sono nulle.\n",
    "Ad esempio, se le classi sono tre e il campione appartiene alla seconda classe ($c = 1$), allora $\\mathbf{y} = [0, 1, 0]$.\n",
    "\n",
    "---\n",
    "\n",
    "### Domanda 3\n",
    "\n",
    "> I vettori \"one-hot\" sono delle valide distribuzioni di probabilità?\n",
    "\n",
    "Sì, i vettori one-hot sono valide distribuzioni di probabilità perché soddisfano le due condizioni fondamentali: tutte le componenti sono non negative e la loro somma è pari a 1. Rappresentano una distribuzione deterministica, in cui tutta la probabilità è assegnata a una sola classe.\n",
    "\n",
    "---\n",
    "\n",
    "Possiamo dunque scrivere la loss relativa a un dato campione $x$ di etichetta one-hot $\\mathbf{y}$ come segue:\n",
    "\n",
    "$$\n",
    "L_\\theta(x, \\mathbf{y}) = -\\sum_i y_i \\log f(x)_i \\tag{9}\n",
    "$$\n",
    "\n",
    "\n",
    "Notiamo che $\\mathbf{y}_i$ sarà uguale a zero tranne che per $i = j$, dove $j$ è la classe del campione $\\mathbf{x}$.\n",
    "Pertanto, solo uno dei termini della sommatoria nella formula sopra sarà non nullo.\n",
    "Ciò ci permette di riscrivere la loss come segue:\n",
    "\n",
    "$$\n",
    "L_\\theta(x, j) = -\\log f(x)_j \\tag{10}\n",
    "$$\n",
    "\n",
    "Dove $j$ è la classe di $\\mathbf{x}$. Ricordando che $f(x) = \\sigma(Ax + b) = \\sigma(z) = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}$, possiamo riscrivere la loss come:\n",
    "\n",
    "$$\n",
    "L_\\theta(x, j) = -\\log \\left( \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}} \\right) = \\log \\sum_{k=1}^K e^{z_k} - \\log e^{z_j} \\tag{11}\n",
    "$$\n",
    "\n",
    "da cui, ricordando che $\\mathbf{z} = A\\mathbf{x} + \\mathbf{b}$, abbiamo:\n",
    "\n",
    "$$\n",
    "L_\\theta(x, j) = \\log \\sum_{k=1}^K e^{z_k} - z_j \\tag{12}\n",
    "$$\n",
    "\n",
    "# 1.1 Implementazione di un Regressore Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d9cdd670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "# Features\n",
    "print(X.shape)\n",
    "\n",
    "# Classi Target\n",
    "print(Y.shape)\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ea64cb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13f0a5fd0>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impostimo un seed per avere risultati ripetibili\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "torch.random.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6803db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7cc7bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[idx]\n",
    "Y = Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "de8437c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "X_training = Tensor(X[30:])\n",
    "Y_training = Tensor(Y[30:])\n",
    "X_testing = Tensor(X[:30])\n",
    "Y_testing = Tensor(Y[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "97cf6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_training.mean(0)\n",
    "X_std = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training - X_mean) / X_std\n",
    "X_testing_norm = (X_testing - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9f97b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class SoftMaxRegressor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super(SoftMaxRegressor, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = self.linear(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e14b5a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9326,  0.6582, -0.2940],\n",
       "        [-0.1301, -0.2885,  0.1746],\n",
       "        [ 1.1440,  1.6170, -1.0236],\n",
       "        [-0.1766, -0.4061,  0.2196],\n",
       "        [-0.4706, -0.5166,  0.2307],\n",
       "        [ 1.2162,  1.5326, -0.9408],\n",
       "        [ 1.6219,  1.6549, -0.9210],\n",
       "        [ 0.8984,  1.2598, -0.8457],\n",
       "        [ 1.4105,  1.9569, -1.2018],\n",
       "        [ 1.0097,  0.5520, -0.2012]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SoftMaxRegressor(4, 3)  # 4 feature in ingresso e 3 classi in uscita\n",
    "model(X_training_norm)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0d35a5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4870, 0.3701, 0.1428],\n",
       "        [0.3116, 0.2659, 0.4225],\n",
       "        [0.3678, 0.5902, 0.0421],\n",
       "        [0.3048, 0.2423, 0.4529],\n",
       "        [0.2518, 0.2405, 0.5077],\n",
       "        [0.4020, 0.5516, 0.0465],\n",
       "        [0.4734, 0.4893, 0.0372],\n",
       "        [0.3831, 0.5499, 0.0670],\n",
       "        [0.3571, 0.6167, 0.0262],\n",
       "        [0.5180, 0.3277, 0.1543]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)  # 1 perché per righe\n",
    "softmax(model(X_training_norm))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "36f60c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(model(X_training_norm)).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318512e",
   "metadata": {},
   "source": [
    "# Domanda 4 \n",
    "Perché è stata calcolata la funzione softmax per righe? \n",
    "\n",
    "La funzione softmax è calcolata per righe (`dim=1`) perché ogni riga rappresenta un campione, e la softmax deve restituire una distribuzione di probabilità sulle classi per ciascun campione. In questo modo, i valori di ogni riga vengono normalizzati affinché sommino a 1, interpretandoli come probabilità che il campione appartenga a ciascuna classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3814233c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "        0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 0, 1, 2, 1, 2, 1, 0,\n",
       "        0, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 1, 0, 0,\n",
       "        1, 2, 0, 2, 2, 0, 1, 2, 2, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1,\n",
       "        1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La funziona max restituisce i valori dei massimi e i loro indici (il risultato della funzione argmax)\n",
    "# per questo includiamo \"[1]\" nell'equazione successiva\n",
    "\n",
    "preds = softmax(model(X_training_norm)).max(1)[1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "77425eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(Y_training, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "413ed787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 1, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2,\n",
      "        0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 0, 2, 2, 0, 1, 2, 1, 2, 1, 0,\n",
      "        0, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 1, 0, 0,\n",
      "        1, 2, 0, 2, 2, 0, 1, 2, 2, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1,\n",
      "        1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "preds_logits = model(X_training_norm).argmax(1)\n",
    "print(preds_logits)\n",
    "print((preds_logits == preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758d0bb",
   "metadata": {},
   "source": [
    "In pratica, si preferisce dunque non applicare la funzione softmax per il calcolo delle etichette predette.\n",
    "\n",
    "La procedura di training del regressore logistico sarà la seguente:\n",
    "\n",
    "1. Normalizzare i dati in ingresso x;\n",
    "2. Costruire il modulo che implementa il modello (il costruttore si preoccuperà di inizializzare i parametri);\n",
    "3. Mettere il modello in modalità \"training\";\n",
    "4. Calcolare l'output del modello ŷ;\n",
    "5. Calcolare il valore della loss ℒₜₕₑₜₐ(x, y);\n",
    "6. Calcolare il gradiente della loss rispetto ai parametri del modello;\n",
    "7. Aggiornare i pesi θ utilizzando il gradient descent;\n",
    "8. Ripetere i passi 4–7 fino a convergenza.\n",
    "\n",
    "Implementiamo la procedura includendo il monitoring delle curve mediante tensorboard e il calcolo dell'accuracy ad ogni iterazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a0d50c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import SGD\n",
    "\n",
    "writer = SummaryWriter(\"logs/softmax_regressor\")\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "means = X_training.mean(0)\n",
    "stds = X_training.std(0)\n",
    "\n",
    "X_training_norm = (X_training - means) / stds\n",
    "X_testing_norm = (X_testing - means) / stds\n",
    "\n",
    "model = SoftMaxRegressor(4, 3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr)\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    out = model(X_training_norm)\n",
    "    l = criterion(out, Y_training.long())\n",
    "    l.backward()\n",
    "    writer.add_scalar(\"loss/train\", l.item(), global_step=e)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds_train = out.max(1)[1]\n",
    "    writer.add_scalar(\n",
    "        \"accuracy/train\", accuracy_score(Y_training, preds_train), global_step=e\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        out = model(X_testing_norm)\n",
    "        l = criterion(out, Y_testing.long())\n",
    "        writer.add_scalar(\"loss/test\", l.item(), global_step=e)\n",
    "        preds_test = out.max(1)[1]\n",
    "        writer.add_scalar(\n",
    "            \"accuracy/test\", accuracy_score(Y_testing, preds_test), global_step=e\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "228c76b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy di training  0.8666666666666667\n",
      "Accurancy di testing  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "preds_train = model(X_training_norm).max(1)[1]\n",
    "preds_test = model(X_testing_norm).max(1)[1]\n",
    "print(\"Accurancy di training \", accuracy_score(Y_training, preds_train))\n",
    "print(\"Accurancy di testing \", accuracy_score(Y_testing, preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d711ef6",
   "metadata": {},
   "source": [
    "# 2. Datasets, Data Loaders, Stochastic Gradient Descent, Salvataggio e Caricamento dei modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb96745",
   "metadata": {},
   "source": [
    "Inizialmente, il gradiente viene calcolato sull'intero dataset (Batch Gradient Descent), ma questo approccio può diventare impraticabile per dataset molto grandi. Per ovviare al problema, si utilizza lo Stochastic Gradient Descent (SGD), che suddivide i dati in mini-batch e calcola il gradiente su uno alla volta. Come esempio, viene introdotto il dataset MNIST, composto da 70.000 immagini di cifre scritte a mano (28×28 pixel), suddivise in 60.000 per il training e 10.000 per il test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "dba9afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_train = MNIST(\n",
    "    root=\"data\", train=True, download=True\n",
    ")  # Train=True indica che vogliamo caricare il training set\n",
    "mnist_test = MNIST(root=\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "33bf7fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di campioni di training:  60000\n",
      "Numero di campioni di testing:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di campioni di training: \", len(mnist_train))\n",
    "print(\"Numero di campioni di testing: \", len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "1c3990c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x3488C26A0>, 5)\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x3488C2730>, 7)\n",
      "<class 'PIL.Image.Image'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train[0])\n",
    "print(mnist_test[0])\n",
    "\n",
    "print(type(mnist_train[0][0]))\n",
    "print(type(mnist_train[0][1]))\n",
    "\n",
    "# Il primo parametro è un immagine il secondo l'etichetta corrispondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c7db2325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(mnist_train[0][0], cmap=\"gray\")\n",
    "plt.title(\"Classe: \" + str(mnist_train[0][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7461b84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = torch.from_numpy(np.array(mnist_train[0][0]))\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "d412c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mnist_train = MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "mnist_test = MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "4104cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "sample = mnist_train[0]\n",
    "print(type(sample[0]))\n",
    "print(type(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "f9cd9a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "86e12d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x550 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5.5))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.title(\"Classe %d\" % mnist_train[i][1])\n",
    "    plt.imshow(mnist_train[i][0].squeeze().numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "2c3dc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizziamo i dati in modo che abbiano media nulla e deviazione standard pari a 1\n",
    "\n",
    "m = 0\n",
    "\n",
    "for sample in mnist_train:\n",
    "    m += sample[0].sum()\n",
    "\n",
    "m = m / (len(mnist_train) * 28 * 28)\n",
    "\n",
    "s = 0\n",
    "\n",
    "for sample in mnist_train:\n",
    "    s += ((sample[0] - m) ** 2).sum()\n",
    "\n",
    "s = np.sqrt(s / (len(mnist_train) * 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e058c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.1307\n",
      "Std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: %0.4f\" % m)\n",
    "print(\"Std: %0.4f\" % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e4b5a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo: tensor(-0.4241)\n",
      "Massimo: tensor(2.8215)\n",
      "Media: tensor(-0.0134)\n",
      "Deviazione Standard: tensor(0.9860)\n"
     ]
    }
   ],
   "source": [
    "sample = (mnist_train[15][0] - m) / s\n",
    "print(\"Minimo:\", sample.min())\n",
    "print(\"Massimo:\", sample.max())\n",
    "print(\"Media:\", sample.mean())\n",
    "print(\"Deviazione Standard:\", sample.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "332a777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possibile non farlo a mano nel seguente modo:\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((m,), (s,))]\n",
    ")\n",
    "mnist_train = MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "mnist_test = MNIST(root=\"data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "9ca8fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo: tensor(-0.4241)\n",
      "Massimo: tensor(2.8215)\n",
      "Media: tensor(-0.0134)\n",
      "Deviazione Standard: tensor(0.9860)\n"
     ]
    }
   ],
   "source": [
    "sample = mnist_train[15][0]\n",
    "print(\"Minimo:\", sample.min())\n",
    "print(\"Massimo:\", sample.max())\n",
    "print(\"Media:\", sample.mean())\n",
    "print(\"Deviazione Standard:\", sample.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "6128fbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "sample = sample.view(-1)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "c7563c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo una funzione custom\n",
    "\n",
    "\n",
    "def custom_transf(x):\n",
    "    return x.view(-1)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((m,), (s,)),\n",
    "        transforms.Lambda(custom_transf),\n",
    "    ]\n",
    ")\n",
    "mnist_train = MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "mnist_test = MNIST(root=\"data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "eeb968cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train[0][0].shape)\n",
    "print(mnist_train[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd4fe7",
   "metadata": {},
   "source": [
    "### 2.2 Data Loader\n",
    "\n",
    "Ogni campione ottenuto mediante l'oggetto dataset MNIST verrà automaticamente normalizzato e trasformato in un vettore. \n",
    "Per effettuare l'ottimizzazione mediante Stochastic Gradient Descent, dobbiamo suddividere i campioni in mini-batch. \n",
    "\n",
    "Inoltre, è importante fornire i campioni in ordine casuale, in quanto fornire consecutivamente elementi con caratteristiche simili \n",
    "(es. stessa classe) favorirebbe l'overfitting.\n",
    "\n",
    "PyTorch ci permette di gestire il \"batching\" in automatico e in maniera multithread mediante l'oggetto DataLoader. \n",
    "\n",
    "Utilizziamo un batch size di 256 immagini e due thread paralleli per velocizzare il caricamento dei dati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8bbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_def",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
