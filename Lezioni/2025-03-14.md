# Venerdì 14 marzo 2025

## COMPITI DI REGRESSIONE

Definiremo il compito di regressione in termini di come l'algoritmo di regressione elabora un determinato esempio di input.

## Definizione del Task

Definiamo un regressore come una funzione:

$$
f: \mathbb{R}^n \rightarrow \mathbb{R}^m
$$

dove $n$ è la dimensionalità dello spazio di input e $m$ è la dimensionalità dello spazio di output.

In generale, denoteremo il vettore di input con $\mathbf{x} \in \mathbb{R}^n$, il vettore di output vero (ground truth) con $\mathbf{y} \in \mathbb{R}^m$, e il vettore di output predetto con $\hat{\mathbf{y}} \in \mathbb{R}^m$.

Possiamo predire un valore da $\mathbf{x}$ nel seguente modo:

$$
\hat{\mathbf{y}} = f(\mathbf{x})
$$

In questo contesto, $\mathbf{x}$ è spesso chiamata **variabile indipendente** e $\mathbf{y}$ **variabile dipendente**.

## Trovare la funzione di regressione $f$

Useremo il paradigma dell'apprendimento automatico per apprendere un regressore adatto $f$. A tal fine, una volta definito il nostro compito, dobbiamo definire un insieme di dati adatto per addestrare e testare i nostri algoritmi. Discuteremo le misure di performance in seguito.

Assumiamo di avere un dataset $D$ di coppie di dati etichettati:

$$
D = { ( x^{(j)}, y^{(j)} ) }_j
$$

Ogni coppia di dati $( x^{(j)}, y^{(j)} )$ è composta da un campione di input $x^{(j)} \in \mathbb{R}^n$ e un valore etichetta di verità $y^{(j)} \in \mathbb{R}^m$. Assumiamo che il dataset sia stato diviso in tre diversi insiemi:

- Un insieme di addestramento $TR = { ( x^{(j)}, y^{(j)} ) }_j$
- Un insieme di validazione $VA = { ( x^{(j)}, y^{(j)} ) }_j$
- Un insieme di test $TE = { ( x^{(j)}, y^{(j)} ) }_j$

---

### Misure di performance

Secondo il paradigma del machine learning, dobbiamo definire una misura per valutare la performance di un dato algoritmo di regressione. Similmente al caso della classificazione, considereremo l'insieme delle etichette di test reali:

$$
Y_{TE} = { y^{(i)} \mid ( x^{(i)}, y^{(i)} ) \in TE }
$$

e l'insieme delle etichette di test previste:

$$
\hat{Y}_{TE} = \{ f(x^{(i)}) \mid ( x^{(i)}, y^{(i)} ) \in TE \}
$$

Idealmente, vorremmo che le etichette previste coincidessero con quelle reali, cioè $\hat{Y}_{TE} = Y_{TE}$. In pratica, definiremo una misura di performance per valutare quanto le nostre previsioni siano vicine ai valori reali.

---

### Errore Quadratico Medio (MSE)

Consideriamo un'etichetta reale $y \in \mathbb{R}^m$ e un'etichetta prevista $\hat{y} \in \mathbb{R}^m$. Dato che entrambi i valori sono vettori di dimensione $m$, un modo naturale per misurare se $\hat{y}$ è una buona approssimazione di $y$ è semplicemente misurare la loro distanza euclidea:

$$
\| \hat{y} - y \|_2 = \sqrt{ \sum_{i=1}^{m} (\hat{y}_i - y_i)^2 }
$$

In pratica, utilizziamo spesso la distanza euclidea al quadrato per penalizzare maggiormente gli errori grandi:

$$
\text{error}(\hat{y}, y) = \| \hat{y} - y \|_2^2 = \sum_{i=1}^{m} (\hat{y}_i - y_i)^2
$$

Possiamo calcolare l’errore medio su tutto l’insieme di test per ottenere un indicatore di performance, che viene solitamente chiamato **Errore Quadratico Medio (MSE)**:

$$
\text{MSE}(Y_{TE}, \hat{Y}_{TE}) = \frac{1}{|TE|} \sum_{j=1}^{|TE|} \| \hat{y}^{(j)} - y^{(j)} \|_2^2
$$

Questa misura di performance è in realtà una **misura di errore**. Un buon regressore otterrà un errore piccolo.
