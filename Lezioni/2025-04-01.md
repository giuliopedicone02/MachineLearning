# Marted√¨ 01 aprile 2025

## Classificazione

Obiettivo: Definire un modello parametrizzato, una funzione costo e un algoritmo di learning utili a trovare in automatico il decision boundary considerando il training set.

La costruzione del training set deve rispecchiare la popolazione delle classi.

![Classification](media/classification.png)

## Classificazione Binaria e Multi Classe

![Classification](media/multiclassClassification.png)


Un modo per trattare problemi multi-classe √® quello di suddividere il problema in tanti problemi binari. Si risolvono i vari problemi binari e si mettono insieme le soluzioni al fine di ottenere la soluzione del problema multiclasse.

Approcci:
- One VS One
- One VS All

### Esempi di classificazione binaria
- Riconoscimento di un tumore al seno (Y={1 se tumore, 0 altrimenti})
- Riconoscimento facciale (Y={1 se presente un volto, 0 altrimenti})
- Spam Detector (Y={1 email spam, 0 altrimenti})

## Possiamo usare il modello di regressione per la classificazione binaria?


### Idea errata

> Se `h(x) ‚â• 0.5` allora assegno classe 1 (es. "caso positivo" o "tumore maligno")
> Altrimenti assegno classe 0 (es. "non tumore maligno")

### Problema:

Un modello di **regressione lineare** pu√≤ assumere **valori arbitrari** (anche negativi o maggiori di 1), che **non hanno significato probabilistico** per la classificazione.

### Esempio grafico:

![Classification](media/regressionclassification.png)


###  A quale classe assegnare un nuovo punto?

* Se `h(x) > 0.5`, lo assegno a **classe positiva**
* Se `h(x) ‚â§ 0.5`, lo assegno a **classe negativa**
* Tuttavia, questa soglia pu√≤ essere **arbitraria o inefficace**.

### Cosa accade se i dati sono molto sbilanciati?

* Aggiungendo **un solo campione sbilanciato**, la retta pu√≤ spostarsi molto.
* Il modello diventa **molto sensibile** ai dati di training.
* La retta **non generalizza bene**.



### ‚ö†Ô∏è Problema principale

Il modello `h(x) = Œ∏·µóx` usato per regressione **non √® vincolato** tra 0 e 1.

### Soluzione: **Logistic Regression**

Si usa la **sigmoid**:

```math
0 ‚â§ hŒ∏(x) ‚â§ 1
```

* Questo garantisce che il modello produca **valori interpretabili come probabilit√†**.
* √à quindi adatto per **problemi di classificazione**.



### ‚úÖ Conclusione

* Un **modello di regressione lineare** **non deve essere usato** per risolvere problemi di classificazione.
* Un **modello di regressione**, opportunamente adattato (es. **regressione logistica**), **pu√≤ essere utile** per problemi di classificazione.


## Regressione Logistica


###  Funzione Sigmoide (Logistic Function)

La funzione sigmoide √® definita come:

```math
\sigma(z) = \frac{1}{1 + e^{-z}}
```

Questa funzione:

* Ha un range limitato tra 0 e 1
* √à **non lineare**
* Ha un'interpretazione **probabilistica**
* √à utilizzata per "mappare" valori reali in probabilit√†

### üìà Grafico della sigmoide

* Quando $z = 0$, $\sigma(z) = 0.5$
* Limite inferiore: $\sigma(z) \to 0$ per $z \to -\infty$
* Limite superiore: $\sigma(z) \to 1$ per $z \to +\infty$


![Classification](media/Sigmoid-Activation-Function.png)

---

## ‚úÖ Modello di Regressione Logistica

Il modello √® definito come:

```math
h_\theta(x) = \sigma(\theta^T x) = \frac{1}{1 + e^{-\theta^T x}}
```

Dove:

* $\theta$ √® il **vettore dei parametri**
* $x$ √® il **vettore delle feature** dell‚Äôinput

---

## üìê Propriet√† della funzione sigmoide $\sigma(z)$

* **Simmetria**:

  ```math
  1 - \sigma(z) = \sigma(-z)
  ```

* **Derivata della sigmoide**:

  ```math
  \frac{d}{dz} \sigma(z) = \sigma(z)(1 - \sigma(z)) = \sigma(z)\sigma(-z)
  ```

* **Forma alternativa** (in termini della funzione tangente iperbolica):

  ```math
  \sigma(z) = \frac{1}{2} + \frac{1}{2} \tanh\left(\frac{z}{2}\right)
  ```

## üìå Interpretazione probabilistica

Il modello logistico pu√≤ essere interpretato come:

```math
h_\theta(x) = P(y = 1 \mid x, \theta)
```

Dunque:

```math
P(y = 1 \mid x, \theta) + P(y = 0 \mid x, \theta)  = 1
```

```math
P(y = 0 \mid x; \theta) = 1 - P(y = 1 \mid x, \theta) = 1 - h_\theta(x) = h_\theta(-x) = \frac{1}{1 + e^{\theta^T x}}
```

---

## üß† Osservazione sul modello logistico 

### üîç Analisi del grafico della funzione sigmoide

![Classification](media/sigmoid.png)


La funzione sigmoide $\sigma(z) = \frac{1}{1 + e^{-z}}$ ha una propriet√† fondamentale:

* Quando $z = 0$, $\sigma(z) = 0.5$ (massima incertezza)
* Quando $z > 0$, $\sigma(z) > 0.5$
* Quando $z < 0$, $\sigma(z) < 0.5$

---

## üéØ Cosa significa questo?

### Se definiamo:

```math
h_\theta(x) = \sigma(\theta^T x)
```

Allora:

* Se $\theta^T x \geq 0$ ‚Üí $h_\theta(x) \geq 0.5$ ‚Üí classe **1**
* Se $\theta^T x < 0$ ‚Üí $h_\theta(x) < 0.5$ ‚Üí classe **0**

Questo implica che la **decisione di classificazione binaria** pu√≤ essere fatta osservando direttamente il **segno** di $\theta^T x$, **senza calcolare la sigmoide**.

> **üí° Osservazione pratica**: durante la fase di **predizione**, possiamo semplificare la classificazione cos√¨:
>
> ```math
> \text{Classe predetta} = \begin{cases}
> 1 & \text{se } \theta^T x \geq 0 \\
> 0 & \text{altrimenti}
> \end{cases}
> ```

## Esempio

Supponiamo di voler classificare punti nel piano $\mathbb{R}^2$ (cio√® coppie $(x_1, x_2)$) in due classi:

* Classe **0**: rappresentata da cerchi (`o`)
* Classe **1**: rappresentata da croci (`x`)

![Classification](media/sigmoid2.png)


## üß† Il modello logistico

Il modello di regressione logistica ha la forma:

$$
\sigma(\theta^T x) = \frac{1}{1 + e^{-\theta^T x}}
$$

Dove:

* $\sigma$ √® la funzione sigmoide
* $\theta \in \mathbb{R}^3$ √® il vettore dei parametri
* $x \in \mathbb{R}^3$ √® il vettore degli input (incluso $x_0 = 1$ per il bias)

### In questo esempio:

$$
\theta = \begin{bmatrix} -3 \\ 1 \\ 1 \end{bmatrix}
$$

quindi la funzione logistica diventa:

$$
\sigma(\theta^T x) = \frac{1}{1 + e^{-(-3 + x_1 + x_2)}}
$$

---

## üî∑ Decision Boundary

La **decision boundary** √® definita dal punto in cui il modello √® incerto, cio√®:

$$
\sigma(\theta^T x) = 0.5 \quad \Rightarrow \quad \theta^T x = 0
$$

Sostituendo i valori:

$$
-3 + x_1 + x_2 = 0 \quad \Rightarrow \quad x_1 + x_2 = 3
$$

Questa √® l'equazione della retta che separa le due classi nel piano.

### Punti che soddisfano la boundary:

* $(x_1, x_2) = (0, 3)$
* $(x_1, x_2) = (3, 0)$

---

## ‚úÖ Regola di classificazione

### Per la classe 1:

$$
\hat{y} = 1 \quad \Leftrightarrow \quad \theta^T x \geq 0 \quad \Leftrightarrow \quad x_1 + x_2 \geq 3
$$

### Per la classe 0:

$$
\hat{y} = 0 \quad \Leftrightarrow \quad \theta^T x < 0 \quad \Leftrightarrow \quad x_1 + x_2 < 3
$$

---

## Regressione Logistica non lineare
$$
\sigma(\theta^T x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_1^2 + \theta_4x_2^2
$$


$$
\theta = \begin{bmatrix} -1 \\ 0 \\ 0 \\ 1 \\ 1 \end{bmatrix}
$$

Il decision boundary √® uguale a: $x_1^2+x_2^2=1$

Gli elementi verranno classificati come:

- Classe 1 se  $x_1^2+x_2^2\geq1$
- Classe 0 se  $x_1^2+x_2^2<1$

![Classification](media/polinomialclassification.png)

Trasformando le feature con un mapping non lineare (es polinomiale) possiamo risolvere problemi di classificazione binaria non separabili da una semplice linea (oppure iperpiani nel caso di d>2)

## Come facciamo a scegliere i parametri $\theta$?


Nel contesto della **classificazione binaria**, il nostro obiettivo √® addestrare un modello affinch√© predica correttamente una variabile target $y \in \{0, 1\}$ a partire da un input $x$. L‚Äôoutput del nostro modello √® una probabilit√† stimata $h_\theta(x) = \hat{y} \in (0, 1)$, ottenuta tipicamente applicando la **sigmoid** all‚Äôoutput lineare.

Per valutare quanto il modello sia distante dalla verit√†, utilizziamo una **funzione di costo** detta **loss function**. Una delle pi√π efficaci per la classificazione binaria √® la **cross-entropy**, definita come:

$$
J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \text{Loss}(h_\theta(x^{(i)}), y^{(i)})
$$

Dove la **loss per singolo esempio** √® definita cos√¨:

$$
\text{Loss}(h_\theta(x), y) =
\begin{cases}
- \log(h_\theta(x)) & \text{se } y = 1 \\
- \log(1 - h_\theta(x)) & \text{se } y = 0
\end{cases}
$$

Questa scelta √® particolarmente potente per vari motivi. Anzitutto, si basa su funzioni **logaritmiche**, che presentano delle propriet√† molto interessanti: sono **derivabili**, **continue** e ‚Äî cosa pi√π importante ‚Äî hanno una crescita **molto rapida** all‚Äôavvicinarsi a zero. Questo significa che **errori gravi** (cio√® assegnare bassa probabilit√† alla classe corretta) vengono penalizzati in modo molto severo, mentre le predizioni corrette vengono premiate con una loss molto piccola o nulla.

![Classification](media/casoy_0.png)
![Classification](media/casoy_1.png)


Per esempio:

* Se $y = 1$ e $h_\theta(x) \to 1$, allora $-\log(h_\theta(x)) \to 0$ (quindi perdita quasi nulla).
* Se invece $h_\theta(x) \to 0$, la perdita $-\log(h_\theta(x)) \to +\infty$.

Allo stesso modo, quando $y = 0$, la loss diventa $-\log(1 - h_\theta(x))$:

* Se $h_\theta(x) \to 0$, allora la loss tende a 0 (ottimo).
* Se $h_\theta(x) \to 1$, la loss esplode a $+\infty$.

![Classification](media/crossEntropy.png)

Questa dinamica permette un **apprendimento efficace**, poich√© guida l‚Äôalgoritmo di ottimizzazione (es. discesa del gradiente) nella giusta direzione, rendendolo **reattivo** soprattutto quando il modello commette errori evidenti.

Per semplificare la scrittura della loss in un‚Äôunica formula, si pu√≤ riscrivere come:

$$
\text{Loss}(h_\theta(x), y) = - y \log(h_\theta(x)) - (1 - y) \log(1 - h_\theta(x))
$$

Questa forma compatta √® molto utile perch√© unifica i due casi $y = 0$ e $y = 1$ in una sola espressione matematica.

La **funzione complessiva di costo** per il modello su tutto il dataset diventa quindi:

$$
J(\theta) = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \right]
$$

Questa funzione √® nota come **funzione di cross-entropy**, ed √® **convessa** quando √® combinata con la sigmoid. La **convessit√†** √® fondamentale: essa garantisce che esista un solo minimo globale e rende molto pi√π efficiente la discesa del gradiente.

√à importante notare che, al contrario, l‚Äôutilizzo della **Mean Squared Error (MSE)** in combinazione con la sigmoid porta a problemi: la funzione di costo **non √® convessa**, la derivata della sigmoid tende a essere molto piccola lontano dallo zero, e questo causa una **discesa del gradiente molto lenta**.

---

### ‚úÖ **Conclusione**

La **cross-entropy loss** √® una scelta ideale per la classificazione binaria perch√©:

* √à **sensibile agli errori**;
* √à **derivabile** e **convessa**;
* Favorisce un **apprendimento pi√π rapido e stabile** rispetto ad altre funzioni di costo come la MSE;
* Integra perfettamente il comportamento della sigmoid, penalizzando le false certezze (cio√® assegnare alta probabilit√† alla classe sbagliata).

In definitiva, questa loss non solo misura l‚Äôerrore, ma **guida l‚Äôapprendimento in modo intelligente**.

## Quale algoritmo usiamo? La Discesa del Gradiente

Serve la derivata della funzione costo della Cross Entropy:

![Classification](media/derivataparziale.png)


## üìâ **Funzione di Costo per la Classificazione Logistica**

### Funzione di costo (Cross-Entropy):

$$
J(\vec{v}) = \frac{1}{m} \sum_{i=1}^{m} \text{Loss}(h_{\vec{v}}(x^{(i)}), y^{(i)}) =
- \frac{1}{m} \left[ \sum_{i=1}^{m} y^{(i)} \log(h_{\vec{v}}(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_{\vec{v}}(x^{(i)})) \right]
$$

---

## üîÅ Derivata della funzione di costo rispetto a $\vec{v}_j$

$$
\frac{\partial J(\vec{v})}{\partial v_j} =
\frac{1}{m} \sum_{i=1}^{m} \left( h_{\vec{v}}(x^{(i)}) - y^{(i)} \right) x_j^{(i)}
\quad \forall j = 0, \ldots, d
$$

---

## ‚ö†Ô∏è **Osservazione importante**

> Attenzione:
> $h_{\vec{v}}(x^{(i)})$ **nasconde** la funzione **sigmoid**:

$$
h_{\vec{v}}(x^{(i)}) = \sigma(\vec{v}^\top x^{(i)})
$$

> Sebbene la forma della derivata sia identica a quella vista per la **regressione lineare**, qui √® applicata alla **classificazione logistica** grazie alla sigmoid.

Certo! Ecco un discorso che riassume e collega i concetti espressi nelle due immagini, adatto per una presentazione, una lezione o uno studio guidato:

---

## Funzione di Costo ed Entropia nella Classificazione


### üß† 1. Funzione di Costo: Cross-Entropy Loss

Partiamo dalla funzione di costo, che √® l'obiettivo da minimizzare durante l'addestramento del modello.
Nel caso della regressione logistica o di una rete neurale con uscita sigmoidale, la funzione di costo usata √®:

$$
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \right]
$$

Questa √® la cross-entropy loss, ed √® costruita in modo da penalizzare fortemente le previsioni sbagliate con alta confidenza.
Ad esempio, se il vero valore √® 1 ma il modello predice una probabilit√† bassa, la perdita √® alta perch√© $\log(h_\theta(x))$ sar√† molto negativo.

---

### üîç 2. Entropia: Misura dell‚ÄôIncertezza

L'entropia, in termini informatici, misura l‚Äôincertezza di una distribuzione. √à definita come:

$$
H(X) = -\sum_{k=1}^{K} p_k \log(p_k)
$$

Se la probabilit√† √® concentrata su una sola classe (es. $p = 1$ e gli altri 0), l'entropia √® minima: nessuna incertezza.
Se invece le probabilit√† sono distribuite equamente (es. $p = 0.5, 0.5$), l'entropia √® massima: massima incertezza.

Questo concetto √® utile per capire quanto "confusa" o "decisa" sia una previsione.

---

### üîÅ 3. Cross-Entropy come Distanza tra Distribuzioni

La cross-entropy misura quanto una distribuzione stimata $q$ si discosta da una distribuzione vera $p$.
Nel contesto del machine learning:

* $p$ √® l‚Äôetichetta vera (ground truth), rappresentata come una distribuzione con 1 nella classe corretta.
* $q$ √® la distribuzione stimata dal classificatore (es. softmax o sigmoid).

La formula √®:

$$
H(p, q) = -\sum_{k} p_k \log(q_k)
$$

Dato che $p_k$ √® 1 solo per la classe corretta, la loss si riduce a:

$$
-\log(q_{\text{corretto}})
$$

In altre parole, stiamo penalizzando il modello quando assegna bassa probabilit√† alla classe corretta.

---

### üìä 4. Analisi dei Casi

Vediamo due situazioni:

* Quando la vera etichetta √® 0: la loss √® $-\log(1 - h_\theta(x))$
* Quando la vera etichetta √® 1: la loss √® $-\log(h_\theta(x))$

In entrambi i casi, pi√π la previsione √® lontana dalla verit√†, pi√π alta √® la perdita.

Questo spiega perch√© la cross-entropy √® una misura efficace per classificazione: non solo penalizza gli errori, ma penalizza anche la sicurezza sbagliata.

### üìå Conclusione

La cross-entropy unisce il concetto matematico di entropia all‚Äôobiettivo pratico del machine learning: fare previsioni corrette e sicure.
Minimizzare la cross-entropy equivale a massimizzare la correttezza e la sicurezza del nostro modello.

Capire questi concetti non solo aiuta a costruire modelli migliori, ma anche a interpretarne il comportamento e le metriche in modo pi√π consapevole.