# GiovedÃ¬ 27 marzo 2025

## Valutazione della Regressione Lineare


### MAE (Errore Assoluto Medio)

Questa metrica calcola lâ€™errore assoluto medio tra le predizioni del modello e i valori osservati nei dati di test. Il MAE fornisce una misura dellâ€™**errore medio tra le predizioni del modello e i valori reali**. Ãˆ utile perchÃ© fornisce una stima diretta della **magnitudo degli errori** nel modello di regressione, indipendentemente dal segno degli errori. Un valore di MAE piÃ¹ basso indica una maggiore accuratezza del modello.

$$
\text{MAE} = \frac{1}{m} \sum_{i=1}^{m} \left| h_{\theta}(x^{(i)}) - y^{(i)} \right|
$$

---

### MSE (Errore Quadratico Medio)

Questa metrica calcola la media dei quadrati degli errori tra le predizioni del modello e i valori osservati. Il MSE **attribuisce un peso maggiore agli errori piÃ¹ grandi** rispetto al MAE, poichÃ© eleva al quadrato ciascun errore. Ãˆ utile perchÃ© penalizza maggiormente gli errori grandi, fornendo cosÃ¬ una misura della **dispersione complessiva degli errori del modello**. Un valore di MSE piÃ¹ basso indica una maggiore accuratezza del modello.

$$
\text{MSE} = \frac{1}{m} \sum_{i=1}^{m} \left( h_{\theta}(x^{(i)}) - y^{(i)} \right)^2
$$

---

### RMSE (Radice dell'Errore Quadratico Medio)

Questa metrica Ã¨ semplicemente la radice quadrata del MSE. Lâ€™RMSE fornisce una misura della **deviazione standard degli errori del modello** ed Ã¨ espressa nella stessa unitÃ  della variabile target. Ãˆ utile perchÃ© fornisce una stima della dispersione degli errori del modello in termini dellâ€™unitÃ  della variabile dipendente. 
Ãˆ una misura di quanto sono dispersi i residui.
Un valore di RMSE piÃ¹ basso indica un miglior adattamento del modello ai dati.

$$
\text{RMSE} = \sqrt{\text{MSE}}
$$

## Rec Curve

Le curve REC forniscono una valutazione delle prestazioni dei modelli di regressione ordinando gli errori di previsione dal piÃ¹ piccolo al piÃ¹ grande e creando dei raggruppamenti cumulativi basati su questi errori. Viene poi tracciata una curva sui raggruppamenti cumulativi degli errori fino a un certo livello, Îµâ‚˜. Questo processo permette di contare il numero di esempi (pattern) che presentano un errore pari o inferiore a un determinato valore, fornendo cosÃ¬ una somma cumulativa degli errori.

L'**area sotto la curva REC (AUC)** rappresenta una misura dell'efficacia dell'algoritmo. Se un modello produce molti errori piccoli, la curva crescerÃ  rapidamente, indicando una maggiore accuratezza nelle previsioni. L'**area sopra la curva (AOC)** fornisce invece una misura dell'errore nelle previsioni.

Per confrontare due modelli, si possono sovrapporre le rispettive curve REC: in generale, il modello con lâ€™area sotto la curva piÃ¹ ampia Ã¨ considerato migliore, poichÃ© indica una maggiore capacitÃ  predittiva e una minore incertezza nei risultati.

![REC CURVE](media/REC_Curve.png)

## Equazione Normale

Il metodo dell'equazione normale trova i parametri ottimali $\Theta$ in un singolo step, risolvendo analiticamente il problema. Siano:

$$
T = \begin{bmatrix}
x_0^{(1)} & x_1^{(1)} & \cdots & x_d^{(1)} \\
x_0^{(2)} & x_1^{(2)} & \cdots & x_d^{(2)} \\
\vdots & \vdots & \ddots & \vdots \\
x_0^{(m)} & x_1^{(m)} & \cdots & x_d^{(m)}
\end{bmatrix}, \quad
y = \begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
\vdots \\
y^{(m)}
\end{bmatrix}
$$

Supponendo che $T^T T$ sia invertibile (altrimenti si utilizza la pseudo-inversa), allora si puÃ² dimostrare che:

$$
\hat{\Theta} = \arg\min_\Theta J(\Theta) = (T^T T)^{-1} T^T y
$$


## Comparazione dei metodi

| Gradiente Discendente | Equazione Normale |
|------------------|--------------------|
| Si deve selezionare il learning rate | Nessun learning rate da selezionare |
| Necessita di molte iterazioni | Ãˆ un metodo diretto |
| Funziona bene anche per tante features | Rallenta molto all'aumentare delle features |
| Nessun calcolo particolarmente pesante | Deve computare un'inversa |
| Consigliato per $d > 1000$ | Consigliato per $d < 1000$ |

## Calcolo dell'equzione normale

![Equazione Normale](media/calcoloEquazioneNormale.png)

## Overfitting e Underfitting


### âš ï¸ **Overfitting**

* Il modello Ã¨ **troppo complesso** rispetto alla quantitÃ  o alla natura dei dati.
* Esempio: usare un polinomio di grado 15 per interpolare solo 5 punti.
* **Effetti**:

  * Basso errore sul **training set**
  * Alto errore su **validation/test set**
  * Il modello â€œimpara a memoriaâ€ i dati di addestramento, ma non sa generalizzare.
* **Cause comuni**:

  1. Numero di feature $\gg$ numero di esempi
  2. Modelli complessi (reti neurali profonde, polinomi di alto grado, ecc.)

---

### âš ï¸ **Underfitting**

* Il modello Ã¨ **troppo semplice** per catturare la struttura dei dati.
* Esempio: usare una retta per dati chiaramente curvilinei.
* **Effetti**:

  * Alto errore sia su **training** che su **validation/test**
  * Il modello non riesce a catturare nemmeno la tendenza generale.

---

### âœ… **Caso ideale (good fit)**

* Il modello ha una **complessitÃ  adeguata**: non troppo semplice, non troppo complesso.
* Cattura le **relazioni vere** nei dati, ma **non il rumore**.
* **Effetti**:

  * Basso errore su training set
  * Basso errore su validation/test set
  * Il modello generalizza bene

La soluzione al fine di evitare l'overfitting Ã¨ la **Regolarizzazione**.

![Under/Over Fitting](media/underoverfitting.png)

## Regolarizzazione

**Obiettivo:**
Evitare lâ€™overfitting â†’ si aggiunge un termine di regolarizzazione alla funzione costo.

Anche se il numero di features Ã¨ alto, la regolarizzazione:

  * considera comunque tutti i parametri;
  * ma ne riduce il modulo (cioÃ¨ li "schiaccia" verso zero).

  Ci sono due modi per misurare quanto sono grandi i parametri $\theta$:

  * Norma 1: $\|\theta\|_1 = \sum |\theta_j|$
  * Norma 2: $\|\theta\|_2 = \sqrt{\sum \theta_j^2}$

---

![Under/Over Fitting](media/underoverfitting.png)

---

### ðŸ§  Esempio pratico:

Si prende una funzione costo con penalitÃ  sui coefficienti $\theta_3$ e $\theta_4$:

$$
J(\theta) = \frac{1}{2m} \sum (h_\theta(x^{(i)}) - y^{(i)})^2 + 1000 * \theta_3 + 1000 *\theta_4
$$

ðŸ‘‰ Questo significa che piÃ¹ $\theta_3$ e $\theta_4$ sono grandi, piÃ¹ la funzione costo aumenta, anche se il modello si adatta bene ai dati.

---

### ðŸ’¡ Conclusione:

Lâ€™unico modo per minimizzare questa funzione costo Ã¨ fare in modo che:

$$
\theta_3 \approx 0 \quad \text{e} \quad \theta_4 \approx 0
$$

Risultato:

* I termini complessi come $\theta_3 x_1^3$, $\theta_4 x_1^4$ scompaiono,
* Il modello si semplifica automaticamente, evitando lâ€™overfitting.

## Nuova funzione costo regolarizzata

Il goal: Mantenere i valori dei parametri piccoli e provare a semplificare l'ipotesi

$$
J(\Theta) = \frac{1}{2m} \left( \sum_{i=1}^{m} \left( h_\Theta(x^{(i)}) - y^{(i)} \right)^2 \right) + \lambda\sum_{j=1}^{n} \theta_j^2
$$

- La prima parte Ã¨ la funzione costo classica (fit tra $h_\Theta(x)$ e $y$)
- La seconda parte Ã¨ il termine di regolarizzazione
- $\lambda$: parametro di regolarizzazione
  - Controlla il trade-off tra errore e regolarizzazione
  - PiÃ¹ $\lambda$ Ã¨ grande, piÃ¹ pesante sarÃ  la regolarizzazione

> Nota: Se $\lambda$ Ã¨ troppo grande, c'Ã¨ il rischio di underfit (tutti i parametri $\approx 0$)

---

## Problema

Trovare il $\hat{\Theta}$ che minimizza la funzione costo regolarizzata $J(\Theta)$.

---

## Quale algoritmo di learning?

### Gradient Descent

L'aggiornamento del parametro $\theta_j$:

$$
\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\Theta)
$$

### Derivata della funzione costo regolarizzata:

Per $j = 0$ (bias term):

$$
\frac{\partial}{\partial \theta_0} J(\Theta) = \frac{1}{m} \sum_{i=1}^{m} \left( h_\Theta(x^{(i)}) - y^{(i)} \right) x_0^{(i)}
$$

Per $j \geq 1$:

$$
\frac{\partial}{\partial \theta_j} J(\Theta) = \frac{1}{m} \sum_{i=1}^{m} \left( h_\Theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)} + \frac{\lambda}{m} \theta_j
$$

### Riscrittura dellâ€™aggiornamento per $j \geq 1$:

$$
\theta_j := \theta_j \left(1 - \alpha \frac{\lambda}{m} \right) - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} \left( h_\Theta(x^{(i)}) - y^{(i)} \right) x_j^{(i)}
$$

> ðŸ“Œ Questo aiuta a penalizzare parametri troppo grandi e a controllare lâ€™overfitting.





