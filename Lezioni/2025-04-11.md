# VenerdÃ¬ 11 aprile 2025

## Multi-Class Classification

![Multiclass Classification](media/multiclass.png)

* Stai considerando un caso in cui un classificatore deve distinguere tra piÃ¹ di 2 classi (es. Class 1, Class 2, Class 3).
* Viene mostrato un esempio 2D con tre tipi di punti (triangoli, cerchi e quadrati), ciascuno appartenente a una classe diversa.


---

## ðŸ“Š ProbabilitÃ  e Decisione

Nella strategia One VS All si fa il training del classificatore binario per ogni classe k al fine di predire la probabilitÃ .
### Formula:

$$
P(\omega_k | x)
$$

* Ãˆ la **probabilitÃ  a posteriori** della classe $\omega_k$ dato il punto $x$.

### Decision Rule (regola di decisione):

$$
R = \text{max}_{k} \, P(\omega_k | x)
$$

* Il punto $x$ viene assegnato alla **classe con probabilitÃ  a posteriori massima**.
* Questo Ã¨ un approccio **Bayesiano** alla classificazione.

---

## ðŸ“Œ Esempio

$$
\begin{align*}
h_1(x) &= 0.3 \\
h_2(x) &= 0.8 \\
h_3(x) &= 0.1
\end{align*}
\Rightarrow \text{Classificato in } \textbf{Classe 2}
$$

* Gli output $h_k(x)$ sono le uscite dei classificatori.
* Anche se nessuna probabilitÃ  supera 0.5, si sceglie quella **con valore massimo**.

$$
\begin{align*}
h_1(x) &= 0.4 \\
h_2(x) &= 0.2 \\
h_3(x) &= 0.1
\end{align*}
\Rightarrow \text{Classificato in } \textbf{Classe 1}
$$
ðŸ“Œ Nota:

$$
\sum_k h_k(x) \quad \text{puÃ² assumere valori > 1}
$$

* PerchÃ© i classificatori non formano una distribuzione di probabilitÃ .

## ðŸ”€ One-vs-All

![Multiclass Classification](media/onevsall.png)


Ogni classificatore distingue tra:

* **una classe** vs **tutte le altre**.

Esempio:

* $h_1(m) < 0.5$
* $h_2(m) < 0.5$
* $h_3(m) < 0.5$

Regola:
Se $h_2(m) < h_3(m) < h_1(m) \rightarrow$  Classe 1



---

## ðŸ¤¼â€â™‚ï¸ One-vs-One

![Multiclass Classification](media/onevsone.png)


* Si addestrano classificatori per ogni **coppia di classi**:

  $$
  \text{Numero di classificatori} = \frac{K(K-1)}{2}
  $$

  dove $K$ Ã¨ il numero di classi.

* Ogni classificatore decide tra due classi. Alla fine si vota la classe con piÃ¹ vittorie (sistema di voto a maggioranza).

ðŸ“Œ Esempio:
Classi $C_1, C_2, C_3$

* $C_1$ vs $C_2$ â†’ vince $C_1$
* $C_2$ vs $C_3$ â†’ vince $C_3$
* $C_1$ vs $C_3$ â†’ vince $C_1$

Risultato: **Classe $C_1$**

ðŸ“ Nota: i **confini di decisione** sono piÃ¹ precisi in questo schema, ma piÃ¹ costosi da calcolare.

---

## ðŸ“‰ Decisione binaria

![Multiclass Classification](media/binaryclass.png)


Mostra la curva di probabilitÃ  per due classi $C_1$ e $C_2$:

* Dove si incrociano (linea tratteggiata verde) si trova la **decision boundary**.
* Zona in mezzo: **reject region** â†’ valori in cui non Ã¨ possibile decidere con sicurezza.

ðŸ‘‰ Questo suggerisce che a volte, se nessuna classe ha abbastanza confidenza, si puÃ² decidere di **non classificare**.

